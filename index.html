<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="Empower Sequence Labeling with Task-Aware Language Model" />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <link href='https://fonts.googleapis.com/css?family=Roboto:400,400italic,700italic,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Condensed:300,300italic,700,700italic' rel='stylesheet' type='text/css'>

    <title>LM-LSTM-CRF</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/LiyuanLucasLiu/LM-LSTM-CRF">View on GitHub</a>

          <h2 id="project_tagline">Empower Sequence Labeling with Task-Aware Language Model</h2>
            
          <h3 id="project_author">
          <a href="https://liyuanlucasliu.github.io/">Liyuan Liu</a>, <a href="http://shangjingbo1226.github.io/">Jingbo Shang</a>, <a href="http://frankxfz.me">Frank F. Xu</a>, <a href="http://xren7.web.engr.illinois.edu/">Xiang Ren</a>, <a href="http://huangui2.web.engr.illinois.edu/">Huan Gui</a>, <a href="http://jianpeng.web.engr.illinois.edu/">Jian Peng</a>, <a href="http://hanj.cs.illinois.edu/">Jiawei Han</a>
          </h3>
        </header>
    </div>

    <section class="outer">
      <div class="downloads inner">
        <a class="zip_download_link" href="https://arxiv.org/pdf/1709.04109.pdf">Paper</a>
        <a class="tar_download_link" href="#Ref">Reference</a>
        <a class="zip_download_link" href="http://lm-lstm-crf.readthedocs.io/en/latest/">Documentation</a>
      </div>
      <p>
    </section>



    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
      <h1>Sequence Labeling</h1>
        <p>
          Linguistic sequence labeling is a general modeling approach that encompasses a variety of problems, such as <em>part-of-speech tagging</em> and <em>named entity recognition</em>.
        </p>

      <h1>Challenges</h1>
        <p>
          Recent advances in neural networks (NNs) make it possible to build reliable models without handcrafted features.
          However, in many cases, it is hard to obtain sufficient annotations to train these models.
        </p>


      <h1>Our Solution</h1>

      <p align="center"><img width="100%" alt="framework" src="docs/framework.png"/></p>

      <p>
        As visualized above, we use conditional random field (CRF) to capture labels' dependency, and adopt hierarchical LSTM to take char-level and word-level input. 
        The char-level structure is further guided by language model, while pre-trained word embedding is leveraged in word-level.
        Language model and sequence labeling made predictions at word-level, and are trained at the same time.
        <a href="https://arxiv.org/abs/1507.06228">Highway networks</a> is used to transform output of char-level into different semantic spaces, which mediates these two tasks and allows language model to empower sequence labeling.
      </p>

      <h1>Experiments</h1>
        <p>
        Here we compare LM-LSTM-CRF with recent sequence labeling models on CoNLL00 Chunking, CoNLL03 NER, and WSJ PTB POS Tagging task. All experiments are conducted on a GTX 1080 GPU.
        </p>

        <h2>NER</h2>

        When only trained the on the CoNLL03 English NER corpus, the results are summarized below:

        <table align="center">
        <caption>Table. 1 Performance on CoNLL03 NER task</caption>
        <tr>
          <th>Method</th>
          <th>Max(F1)</th> 
          <th>Mean(F1)</th>
          <th>Std(F1)</th>
          <th>Reported(F1)</th>
          <th>Time(h)</th>
        </tr>
        <tr>
          <td> <a href="www.aclweb.org/anthology/N16-1030">Lample et al. 2016</a> </td>
          <td> 91.14 </td>
          <td> 90.76 </td>
          <td> 0.08 </td>
          <td> 90.94 </td>
          <td> 46 </td>
        </tr>
        <tr>   
          <td> <a href="www.cs.cmu.edu/~xuezhem/publications/P16-1101.pdf">Ma et al. 2016</a> </td>
          <td> 91.67 </td>
          <td> 91.37 </td>
          <td> 0.17 </td>
          <td> 91.21 </td>
          <td> 7 </td>
        </tr>
        <tr>
          <td> LM-LSTM-CRF (our) </td>
          <td>  <b>91.85</b> </td>
          <td>  <b>91.71</b> </td>
          <td> 0.10 </td>
          <td> </td>
          <td> 6 </td>
        </tr>
        </table>

        <h2>POS</h2>

        When only trained the on WSJ portion of PTB POS Tagging corpus, the results are summarized below:

        <table align="center">
        <caption>Table. 2 Performance on WSJ-PTB POS-Tagging task</caption>
        <tr>
          <th>Method</th>
          <th>Max(F1)</th> 
          <th>Mean(F1)</th>
          <th>Std(F1)</th>
          <th>Reported(F1)</th>
          <th>Time(h)</th>
        </tr>
        <tr>
          <td> <a href="www.aclweb.org/anthology/N16-1030">Lample et al. 2016</a> </td>
          <td> 97.51 </td>
          <td> 97.35 </td>
          <td> 0.09 </td>
          <td> </td>
          <td> 37 </td>
        </tr>
        <tr>   
          <td> <a href="www.cs.cmu.edu/~xuezhem/publications/P16-1101.pdf">Ma et al. 2016</a> </td>
          <td> 97.46 </td>
          <td> 97.42 </td>
          <td> 0.04 </td>
          <td> 97.55 </td>
          <td> 21 </td>
        </tr>
        <tr>
          <td> LM-LSTM-CRF (our) </td>
          <td> <b>97.59</b> </td>
          <td> <b>97.53</b> </td>
          <td> 0.03 </td>
          <td> </td>
          <td> 16 </td>
        </tr>
        </table>

        <h2>Chunking</h2>

        When only trained the on CoNLL00 Chunking corpus, the results are summarized below:

        <table align="center">
        <caption>Table. 2 Performance on CoNLL00 Chunking task</caption>
        <tr>
          <th>Method</th>
          <th>Max(F1)</th> 
          <th>Mean(F1)</th>
          <th>Std(F1)</th>
          <th>Time(h)</th>
        </tr>
        <tr>
          <td> <a href="www.aclweb.org/anthology/N16-1030">Lample et al. 2016</a> </td>
          <td> 94.49 </td>
          <td> 94.37 </td>
          <td> 0.07 </td>
          <td> 26 </td>
        </tr>
        <tr>   
          <td> <a href="www.cs.cmu.edu/~xuezhem/publications/P16-1101.pdf">Ma et al. 2016</a> </td>
          <td> 95.93 </td>
          <td> 95.80 </td>
          <td> 0.13 </td>
          <td> 6 </td>
        </tr>
        <tr>
          <td> LM-LSTM-CRF (our) </td>
          <td> <b>96.13</b> </td>
          <td> <b>95.96</b> </td>
          <td> 0.08 </td>
          <td> 5 </td>
        </tr>
        </table>

      <h1 id="Ref">Reference</h1>

      <p>
      Please cite the following paper if you find the codes and datasets useful:
      </p>

      <p id="reference">
      @ARTICLE{2017arXiv170904109L,<br>
      &nbsp title = "{Empower Sequence Labeling with Task-Aware Neural Language Model}", <br>
      &nbsp author = {{Liu}, L. and {Shang}, J. and {Xu}, F. and {Ren}, X. and {Gui}, H. and {Peng}, J. and {Han}, J.}, <br>
      &nbsp journal = {ArXiv e-prints}, <br>
      &nbsp archivePrefix = "arXiv", <br>
      &nbsp eprint = {1709.04109}, <br>
      &nbsp year = 2017, <br>
      &nbsp month = sep, <br>
      &nbsp adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170904109L}, <br>
      }</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">    
        <p>
          <a href="http://www.hitwebcounter.com" target="_blank">
          <img src="http://hitwebcounter.com/counter/counter.php?page=6760300&style=0006&nbdigits=8&type=page&initCount=0" title="hit counts" Alt="hit counts" border="0" >
          </a>                                           
        </p>
        <p class="copyright">by <a href="https://github.com/jasoncostello">Slate Theme</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

  </body>
</html>
